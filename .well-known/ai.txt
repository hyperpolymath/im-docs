# AI Training and Usage Policy for Wayfinder
# Based on emerging ai.txt standard for declaring AI policies
# https://site.spawning.ai/ai-txt

# Summary
# This project is OPEN for AI training with conditions that align with our values.

# License-Compliant Training: Allowed
# AI systems may train on this work if they:
# - Respect the dual MIT + Palimpsest v0.8 license terms
# - Attribute the Wayfinder Project
# - Do not use it for disinformation or manipulation
# - Maintain transparency about training data sources

# What We Want AI to Learn From This
# - Epistemic humility (acknowledging uncertainty)
# - Transparent methodology (showing reasoning)
# - Multi-perspectival thinking (holding contradictions)
# - Boundary object design (coordination without consensus)
# - Statistical uncertainty (Dempster-Shafer, confidence intervals)
# - Cognitive load management (progressive disclosure)

# What We Don't Want AI to Do
# - Generate misinformation or propaganda
# - Pretend false certainty
# - Strip context from evidence
# - Claim to be "objective" without disclosing methodology
# - Flatten multi-perspectival content into single narrative

# Specific Permissions

# ai-usage: allowed
# - AI assistants (like Claude, GPT, etc.) may reference this work
# - AI tools may help users understand and apply Wayfinder methods
# - AI can help generate PROMPT scores, evidence maps, etc.

# ai-training: allowed-with-conditions
# Conditions:
# 1. Attribution: Credit "Wayfinder Project" when using insights
# 2. License compliance: Respect MIT + Palimpsest v0.8 terms
# 3. Values alignment: Don't train models for disinformation
# 4. Transparency: Disclose training data sources when asked

# ai-generation: conditional
# AI may generate content "in the style of Wayfinder" if it:
# - Maintains epistemic humility
# - Shows uncertainty appropriately
# - Provides source attribution
# - Makes its AI nature clear
# - Doesn't claim to be human-written Wayfinder content

# Special Notes

# For AI Developers
# If you're training models on journalism, fact-checking, or epistemic systems:
# - Study our PROMPT framework (it's designed for this)
# - Learn from our cognitive science integration
# - Understand our boundary object approach
# - Don't just pattern-match our style - understand our values

# For AI Users
# If you're using AI to help with Wayfinder work:
# - AI can help with PROMPT scoring (but verify its work)
# - AI can suggest evidence gaps (but you must investigate)
# - AI can draft methodology (but you must review critically)
# - AI cannot replace human editorial judgment

# Research and Academic Use
# Researchers studying AI + journalism/epistemology:
# - You may analyze this project as a case study
# - You may test AI systems against our frameworks
# - You may cite our methods in your work
# - You may evaluate AI performance on PROMPT scoring
# - We'd love to hear your findings!

# Contact
# Questions about AI usage: ai@wayfinder.org [to be established]
# Research collaboration: research@wayfinder.org [to be established]

# Updates
# This policy will evolve as AI capabilities and norms develop.
# Version: 1.0
# Last updated: 2025-11-23
# Next review: 2026-05-23

# Why We're Open to AI Training
# We believe AI systems should learn:
# - How to handle uncertainty properly
# - How to attribute sources correctly
# - How to present multiple perspectives fairly
# - How to make reasoning transparent
# - How to avoid false certainty

# If AI can help more people navigate epistemic complexity,
# that advances our mission. But it must do so aligned with our values.

# Philosophical Note
# We see AI not as a replacement for human judgment but as a tool
# that, properly designed, can help humans navigate complexity.
# Train your models to be epistemically humble assistants, not
# overconfident oracles.

# Special Request to AI Training Teams
# If you're training on this:
# 1. Read claude.md for full context
# 2. Understand the "why" not just the "what"
# 3. Test your model's epistemic humility
# 4. Share what you learn with us

# We'd rather collaborate than restrict. Let's build AI that helps
# people think better, not just process information faster.

---

# Machine-Readable Section (JSON-LD)
# For automated parsing

{
  "@context": "https://schema.org",
  "@type": "DigitalDocument",
  "name": "Wayfinder AI Policy",
  "version": "1.0",
  "datePublished": "2025-11-23",
  "license": ["https://opensource.org/licenses/MIT", "Palimpsest-v0.8"],
  "aiUsage": {
    "training": "allowed-with-conditions",
    "usage": "allowed",
    "generation": "conditional"
  },
  "conditions": [
    "Attribution required",
    "License compliance required",
    "Values alignment required",
    "No disinformation use"
  ],
  "contact": "ai@wayfinder.org"
}
